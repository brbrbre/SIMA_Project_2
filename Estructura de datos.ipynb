{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Concatenación completa\n",
      " - Filas: 136,983\n",
      " - Columnas: 17\n",
      " - Estaciones: ['CENTRO', 'SUROESTE', 'SUROESTE2']\n",
      " - Rango de fechas: 2020-01-01 00:00:00  →  2024-07-31 23:00:00\n",
      " - CSV:  Bases_Datos/datos_anios.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Concatena datos de las estaciones CENTRO, SUROESTE y SUROESTE2\n",
    "de los archivos.\n",
    "Estandariza la dirección del viento a 'WD' y deja el orden de columnas como:\n",
    "Fecha, Estacion, CO, NO, NO2, NOX, O3, PM10, PM2.5, PRS, RAINF, RH, SO2, SR, TOUT, WSR, WD, ...\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FILE_2020_2021 = Path(\"Bases_Datos/Datos2020-2021.xlsx\")\n",
    "FILE_2022_2023 = Path(\"Bases_Datos/Datos2022-2023.xlsx\")\n",
    "FILE_2023_2024 = Path(\"Bases_Datos/Datos2023-2024.xlsx\")\n",
    "\n",
    "# Estaciones a incluir\n",
    "STATIONS = [\"CENTRO\", \"SUROESTE\", \"SUROESTE2\"]\n",
    "\n",
    "OUT_CSV  = Path(\"Bases_Datos/datos_anios.csv\")\n",
    "\n",
    "# Sinónimos a estandarizar -> WD\n",
    "RENAME_EQUIV = {\n",
    "    \"WDV\": \"WD\",\n",
    "    \"WDR\": \"WD\",\n",
    "    \"WDR/WD\": \"WD\",\n",
    "    \"WDR/WDV\": \"WD\",\n",
    "    \"WIND_DIR\": \"WD\",\n",
    "}\n",
    "\n",
    "PREFERRED_PARAM_ORDER = [\n",
    "    \"CO\",\"NO\",\"NO2\",\"NOX\",\"O3\",\"PM10\",\"PM2.5\",\"PRS\",\"RAINF\",\"RH\",\"SO2\",\"SR\",\"TOUT\",\"WSR\",\"WD\"\n",
    "]\n",
    "\n",
    "def detect_date_col(df: pd.DataFrame):\n",
    "    for c in df.columns:\n",
    "        cl = str(c).strip().lower()\n",
    "        if cl in (\"date\", \"fecha\", \"time\", \"hora\", \"datetime\"):\n",
    "            return c\n",
    "    for c in df.columns:\n",
    "        if \"date\" in str(c).lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def unify_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estandariza nombres equivalentes (WD variantes -> WD).\n",
    "    No cambia otros nombres para respetar tu nomenclatura original.\n",
    "    \"\"\"\n",
    "    rename_map = {c: RENAME_EQUIV[c] for c in df.columns if c in RENAME_EQUIV}\n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "def order_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ordena columnas: Fecha, Estacion, luego parámetros en PREFERRED_PARAM_ORDER\n",
    "    y al final cualquier columna restante (en orden alfabético para consistencia).\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "    left = [c for c in [\"Fecha\", \"Estacion\"] if c in cols]\n",
    "    preferred = [c for c in PREFERRED_PARAM_ORDER if c in cols]\n",
    "    rest = [c for c in cols if c not in set(left + preferred)]\n",
    "    rest_sorted = sorted(rest)  \n",
    "    new_order = left + preferred + rest_sorted\n",
    "    return df.reindex(columns=new_order)\n",
    "\n",
    "def tidy_by_sheet(file_path: Path, stations):\n",
    "    \"\"\"\n",
    "    Lee un archivo donde cada hoja es una estación (mismas columnas),\n",
    "    renombra la columna de fecha a 'Fecha', agrega 'Estacion' y unifica WD.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for st in stations:\n",
    "        df = pd.read_excel(file_path, sheet_name=st)\n",
    "        date_col = detect_date_col(df)\n",
    "        if date_col is None:\n",
    "            raise ValueError(f\"No se encontró columna de fecha en {file_path.name}/{st}\")\n",
    "        df = df.rename(columns={date_col: \"Fecha\"})\n",
    "        df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], errors=\"coerce\")\n",
    "        df[\"Estacion\"] = st\n",
    "        df = unify_column_names(df)\n",
    "        out.append(df)\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "def tidy_param_horarios(file_path: Path, stations):\n",
    "    \"\"\"\n",
    "    La hoja Param_horarios_Estaciones está en formato ancho:\n",
    "      - Fila 0: nombre de estación repetido por bloque de variables (p. ej. 'CENTRO')\n",
    "      - Fila 1: nombres de las variables (CO, NO, NO2, ...)\n",
    "      - Fila 2: unidades (ppm, ppb, etc.) -> se ignoran\n",
    "      - Columna 0: 'date' (fila 2 contiene el texto 'date'; los datos empiezan en la fila 3)\n",
    "    Toma solo los bloques de las estaciones solicitadas y devuelve un DataFrame \"largo\".\n",
    "    \"\"\"\n",
    "    raw = pd.read_excel(file_path, sheet_name=\"Param_horarios_Estaciones\", header=None)\n",
    "\n",
    "    data_start_row = 3  # después de 'date' (fila 2)\n",
    "    date_series = pd.to_datetime(raw.iloc[data_start_row:, 0], errors=\"coerce\")\n",
    "\n",
    "    parts = []\n",
    "    for st in stations:\n",
    "        cols_idx = raw.columns[(raw.iloc[0, :] == st)].tolist()\n",
    "        if not cols_idx:\n",
    "            continue\n",
    "        param_names = raw.iloc[1, cols_idx].tolist()\n",
    "        df_st = raw.iloc[data_start_row:, cols_idx].copy()\n",
    "        df_st.columns = param_names\n",
    "        df_st.insert(0, \"Fecha\", date_series.values)\n",
    "        df_st[\"Estacion\"] = st\n",
    "        df_st = unify_column_names(df_st)\n",
    "        parts.append(df_st)\n",
    "\n",
    "    if not parts:\n",
    "        return pd.DataFrame(columns=[\"Fecha\", \"Estacion\"])\n",
    "\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "def main():\n",
    "    tidy_2020_2021 = tidy_by_sheet(FILE_2020_2021, STATIONS)\n",
    "    tidy_2022_2023 = tidy_by_sheet(FILE_2022_2023, STATIONS)\n",
    "\n",
    "    tidy_2023_2024 = tidy_param_horarios(FILE_2023_2024, STATIONS)\n",
    "\n",
    "    # Alinear columnas por unión\n",
    "    all_cols = sorted(set().union(\n",
    "        *[df.columns for df in [tidy_2020_2021, tidy_2022_2023, tidy_2023_2024]]\n",
    "    ))\n",
    "    tidy_2020_2021 = tidy_2020_2021.reindex(columns=all_cols)\n",
    "    tidy_2022_2023 = tidy_2022_2023.reindex(columns=all_cols)\n",
    "    tidy_2023_2024 = tidy_2023_2024.reindex(columns=all_cols)\n",
    "\n",
    "    # Concatenar\n",
    "    df_all = pd.concat([tidy_2020_2021, tidy_2022_2023, tidy_2023_2024], ignore_index=True)\n",
    "\n",
    "    # Limpieza: descartar filas sin fecha y ordenar\n",
    "    df_all = df_all[~df_all[\"Fecha\"].isna()].copy()\n",
    "    df_all = df_all.sort_values([\"Estacion\", \"Fecha\"]).reset_index(drop=True)\n",
    "\n",
    "    df_all = order_columns(df_all)\n",
    "\n",
    "    # Guardar resultados\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_all.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
